from elasticsearch import AsyncElasticsearch
from aiogram import Bot
import pandas as pd
from sklearn.ensemble import IsolationForest
import numpy as np
import re
import asyncio
from dotenv import load_dotenv
import logging
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
import pytz
import os
import sys

sys.stdout = open('/var/log/app_out.log', 'a')
sys.stderr = open('/var/log/app_err.log', 'a')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

load_dotenv()
ELASTICSEARCH_HOST = os.getenv('ELASTICSEARCH_HOST', 'elasticsearch')
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

if not all([TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID]):
    logger.critical("–ù–µ –∑–∞–¥–∞–Ω—ã TELEGRAM_BOT_TOKEN –∏–ª–∏ TELEGRAM_CHAT_ID –≤ .env")
    exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML-–º–æ–¥–µ–ª–∏
model = IsolationForest(
    n_estimators=100,
    contamination=0.01,
    random_state=42
)

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Elasticsearch
es = AsyncElasticsearch([f'http://{ELASTICSEARCH_HOST}:9200'])
bot = Bot(token=TELEGRAM_BOT_TOKEN)

DANGEROUS_PATTERNS = [
    r'drop\s+database',
    r'truncate\s+table',
    r'delete\s+from\s+\w+\s*(?!where)',
    r'alter\s+table\s+\w+\s+drop',
    r';\s*--',
    r'1\s*=\s*1',
    r'union\s+select',
    r'insert\s+into\s+\w+\s+values',
    r'update\s+\w+\s+set\s+\w+\s*=\s*\w+\s*(?!where)'
]


def extract_features(query):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    return np.array([
        len(query),
        len(re.findall(r'\bSELECT\b', query, re.IGNORECASE)),
        len(re.findall(r'\bWHERE\b', query, re.IGNORECASE)),
        len(re.findall(r'\bJOIN\b', query, re.IGNORECASE)),
        len(re.findall(r';--', query)),
        len(re.findall(r'\bUNION\b', query, re.IGNORECASE))
    ]).reshape(1, -1)

async def train_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    await asyncio.sleep(10)
    try:
        query = {
            "query": {"match_all": {}},
            "size": 100,
            "sort": [{"@timestamp": {"order": "desc"}}]
        }
        res = await es.search(index="postgresql-logs-*", body=query)

        queries = [
            hit["_source"].get("query", "")
            for hit in res["hits"]["hits"]
            if hit["_source"].get("query")
        ]

        if not queries:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False

        X = np.array([extract_features(q) for q in queries])
        model.fit(X)
        logger.info(f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ {len(queries)} –∑–∞–ø–∏—Å—è—Ö")
        return True

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        await send_alert(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        return False

def check_dangerous_queries(query):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    if not hasattr(model, 'estimators_'):
        return False, "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"

    query_lower = query.lower()
    for pattern in DANGEROUS_PATTERNS:
        if re.search(pattern, query_lower):
            return True, pattern

    try:
        features = extract_features(query)
        prediction = model.predict(features)
        if prediction[0] == -1:
            return True, "ML-–∞–Ω–æ–º–∞–ª–∏—è"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        return False, str(e)

    return False, None

async def send_alert(message):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è"""
    try:
        await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")


async def check_connections():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–æ—Ç–∞
        await bot.get_me()
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Elasticsearch
        if not await es.ping():
            raise ConnectionError("Elasticsearch –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        logger.info("–í—Å–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã")
        return True
    except Exception as e:
        logger.critical(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π: {e}")
        await send_alert(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        exit(1)


async def monitor_logs():
    """–û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    try:
        if not await check_connections():
            return

        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ —Ñ–∞–π–ª–∞
        try:
            with open('last_checked_time.txt', 'r') as f:
                last_checked_time = f.read().strip() or None
        except FileNotFoundError:
            last_checked_time = None

        query = {
            "query": {
                "range": {
                    "@timestamp": {
                        "gt": last_checked_time,
                        "format": "strict_date_optional_time"
                    }
                }
            },
            "sort": [{"@timestamp": {"order": "asc"}}]
        }

        res = await es.search(index="postgresql-logs-*", body=query)

        if res['hits']['hits']:
            new_last_time = res['hits']['hits'][-1]['_source']['@timestamp']

            with open('last_checked_time.txt', 'w') as f:
                f.write(new_last_time)

            for hit in res['hits']['hits']:
                source = hit['_source']
                query_text = source.get('query', '')
                user = source.get('user', 'N/A')
                database = source.get('database', 'N/A')
                timestamp = source['@timestamp']

                if query_text:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                    is_dangerous, reason = check_dangerous_queries(query_text)
                    if is_dangerous:
                        message = (
                            f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∞–Ω–æ–º–∞–ª–∏—è!\n\n"
                            f"‚è± –í—Ä–µ–º—è: {timestamp}\n"
                            f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user}\n"
                            f"üóÑ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {database}\n"
                            f"üîç –ü—Ä–∏—á–∏–Ω–∞: {reason}"
                        )
                        await send_alert(message)

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {str(e)}"
        logger.error(error_msg)
        await send_alert(error_msg)

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
    await check_connections()

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
    trained = False
    for attempt in range(3):
        try:
            await train_model()
            trained = True
            break
        except Exception as e:
            logger.error(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            await asyncio.sleep(5)

    if not trained:
        logger.critical("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
        await send_alert("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
        return

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    scheduler = AsyncIOScheduler(timezone=pytz.timezone("Europe/Moscow"))
    scheduler.add_job(
        monitor_logs,
        IntervalTrigger(seconds=30),
        max_instances=1
    )
    scheduler.start()

    while True:
        await asyncio.sleep(1)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    finally:
        asyncio.run(es.close())
        asyncio.run(bot.session.close())
# –¢–µ—Å—Ç–æ–≤—ã–π commit